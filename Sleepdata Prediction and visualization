import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import KNNImputer

df = pd.read_csv('dataset_2191_sleep.csv')

def clean_data(df):
    df = df.replace(['?'], np.nan)
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

def impute_missing(df):
    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
    if len(numerical_cols) > 0:
        imputer = KNNImputer(n_neighbors=2)
        df[numerical_cols] = imputer.fit_transform(df[numerical_cols])
    return df

def model_fitting(models, X_train, y_train, X_test, y_test):
    result = {}
    for name, model in models:
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        mse = mean_squared_error(y_test, predictions, multioutput='raw_values')
        r2 = r2_score(y_test, predictions, multioutput='raw_values')
        result[name] = {
            'predictions': predictions,
            'mean_squared_error': mse,
            'r2_score': r2}
    return result

def plot_results(y_test, results, required_columns):
    for name, result in results.items():
        if 'predictions' not in result:
            print(f"Error: No predictions for model {name}")
            continue
        for i, column in enumerate(required_columns):
            plt.figure(figsize=(8, 6))
            plt.scatter(range(len(y_test)), y_test.iloc[:, i], color='blue', label='Actual Values', alpha=0.6)
            plt.scatter(range(len(y_test)), result['predictions'][:, i], color='red', label='Predictions', alpha=0.6)
            plt.title(f"{name} - {column}")
            plt.xlabel('Test Sample')
            plt.ylabel(column)
            plt.legend()
            plt.show()

def plot_bar(results, required_columns):
    model_names = list(results.keys())
    n_models = len(model_names)
    colors = ['skyblue', 'lightgreen', 'salmon']
    for i, col in enumerate(required_columns):
        plt.figure(figsize=(10, 6))
        mse_values = []
        for name in model_names:
            if name in results and 'mean_squared_error' in results[name]:
                mse = results[name]['mean_squared_error'][i]
                mse_values.append(mse)
        x = np.arange(n_models)
        for j, (name, mse) in enumerate(zip(model_names, mse_values)):
            plt.bar(x[j], mse, width=0.25, label=name, color=colors[j % len(colors)])
        plt.xticks(x, model_names)
        plt.title(f"MSE Comparison for {col}")
        plt.xlabel('Models')
        plt.ylabel('Mean Squared Error')
        plt.legend()
        plt.show()

df = pd.read_csv(dataset_2191_sleep.csv')
df = (df.pipe(clean_data).pipe(impute_missing))
required_columns = ["predation_index", "sleep_exposure_index", "danger_index"]
if all(col in df.columns for col in required_columns):
    X = df.drop(["predation_index", "sleep_exposure_index", "danger_index"], axis=1)
    y = df[["predation_index", "sleep_exposure_index", "danger_index"]]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)
    models = [
        ('LinearRegression', LinearRegression()),
        ('PolynomialRegression', Pipeline(steps=[
            ('scaler', StandardScaler()),
            ('poly', PolynomialFeatures(degree=3)),
            ('lr', LinearRegression())
        ])),
        ('RandomForest', RandomForestRegressor(criterion='absolute_error', n_estimators=100, random_state=123))]

    results = model_fitting(models, X_train, y_train, X_test, y_test)
    print("Structure of results:")
    for name in results:
        print(f"Model: {name}, Keys: {list(results[name].keys())}")
    plot_results(y_test, results, required_columns)
    plot_bar(results, required_columns)
    for name, result in results.items():
        print(f"\nModel: {name}")
        for i, col in enumerate(required_columns):
            mse = result.get('mean_squared_error', [np.nan] * len(required_columns))[i]
            r2 = result.get('r2_score', [np.nan] * len(required_columns))[i]
            print(f"  {col} - MSE: {mse:.4f}, r2: {r2:.4f}")
